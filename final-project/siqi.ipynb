{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Load packages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data processing packages\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# machine learning packages\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# visualization packages\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# other packages\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import random\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Read the files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Create the necessary folders\n",
    "Path('./Figures/').mkdir(parents=True, exist_ok=True)\n",
    "Path('./Results/').mkdir(parents=True, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Set path to the data set\n",
    "dataset_path = \"./dataset/77_cancer_proteomes_CPTAC_itraq.csv\"\n",
    "clinical_info = \"./dataset/clinical_data_breast_cancer.csv\"\n",
    "pam50_proteins = \"./dataset/PAM50_proteins.csv\"\n",
    "\n",
    "## Load data\n",
    "data = pd.read_csv(dataset_path,header=0,index_col=0)\n",
    "clinical_file = pd.read_csv(clinical_info,header=0,index_col=0) ## holds clinical information about each patient/sample\n",
    "pam50 = pd.read_csv(pam50_proteins,header=0)\n",
    "\n",
    "# RefSeq protein ID (each protein has a unique ID in a RefSeq database)\n",
    "print(data.index.name)\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Data Set Processing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Drop unused information columns\n",
    "data.drop(['gene_symbol','gene_name'],axis=1,inplace=True)\n",
    "\n",
    "## Change the protein data sample names to a format matching the clinical data set\n",
    "data.rename(columns=lambda x: \"TCGA-%s\" % (re.split('[_|-|.]',x)[0]) if bool(re.search(\"TCGA\",x)) is True else x,inplace=True)\n",
    "\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Transpose data for the clustering algorithm since we want to divide patient samples, not proteins\n",
    "print(data.shape)\n",
    "datat = data.transpose()\n",
    "print(datat.shape)\n",
    "\n",
    "datat.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Number of patients in clinical data set: \", len(clinical_file.index))\n",
    "print(\"Number of patients in protein data set: \", len(datat.index))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Drop clinical entries for samples not in our protein data set\n",
    "clinical = clinical_file.loc[[x for x in clinical_file.index.tolist() if x in datat.index],:]\n",
    "\n",
    "print(\"The shape of the clinical data set: \", clinical.shape)\n",
    "clinical.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Add clinical meta data to our protein data set, note: all numerical features for analysis start with NP_ or XP_\n",
    "merged = datat.merge(clinical,left_index=True,right_index=True)\n",
    "\n",
    "# Drop the duplicated columns (added by Pietro Gavazzi)\n",
    "liste = merged.index.copy()\n",
    "liste = list(liste)\n",
    "\n",
    "for i in np.unique(merged.index):\n",
    "    liste.remove(i)\n",
    "\n",
    "## Change name to make it look nicer in the code!\n",
    "processed = merged.drop(np.unique(liste))\n",
    "\n",
    "print(\"Shape of the merged data set: \", processed.shape)\n",
    "print(\"with %d patients and %d features\" % (processed.shape[0], processed.shape[1]))\n",
    "\n",
    "processed.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Numerical data for the algorithm, NP_xx/XP_xx are protein identifiers from RefSeq database\n",
    "X = processed.loc[:,[x for x in processed.columns if bool(re.search(\"NP_|XP_|YP_\",x)) == True]]\n",
    "Y = pd.get_dummies(processed.drop(X.columns, axis=1)['Integrated Clusters (with PAM50)'], prefix=\"PAM50\")\n",
    "\n",
    "## Select only the PAM50 proteins - known panel of genes used for breast cancer subtype prediction\n",
    "# processed_numerical_p50 = processed_numerical.iloc[:,processed_numerical.columns.isin(pam50['RefSeqProteinID'])]\n",
    "# processed_numerical_p50.head()\n",
    "\n",
    "X.columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Y.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save the data\n",
    "torch.save(X, './Results/X')\n",
    "torch.save(Y, './Results/Y')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Data Engineering"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read the processed data set\n",
    "X = torch.load('./Results/X')\n",
    "Y = torch.load('./Results/Y')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Y.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1 Missing value process\n",
    "We drop all the columns with nan values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nan_counts = np.sum(X.isna(), axis=0)\n",
    "col_to_drop = nan_counts[nan_counts != 0].index\n",
    "X.drop(col_to_drop, axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2 Data Scaling\n",
    "We use the standardization for each feature of the data set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "col_names = X.columns\n",
    "idx = X.index\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=col_names, index=idx)\n",
    "X_scaled.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Basic model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.1 K-Means model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4, algorithm='full').fit(X_scaled)\n",
    "pred = kmeans.labels_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.2 Evaluation Metric"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "permutation_matrices = []\n",
    "for i in itertools.permutations([0, 1, 2, 3]):\n",
    "    matrix = np.zeros((4, 4))\n",
    "    for j in range(len(matrix)):\n",
    "        matrix[j][i[j]] = 1\n",
    "\n",
    "    permutation_matrices.append(matrix)\n",
    "\n",
    "def model_eval(y_true, y_pred, return_permutation=False, plot=False):\n",
    "    pred = pd.DataFrame(pd.get_dummies(y_pred))\n",
    "    pred.columns = ['cluster_' + str(x) for x in range(1, 5)]\n",
    "    pred = pred.set_index(y_true.index)\n",
    "    merged = y_true.merge(pred, right_index=True, left_index=True)\n",
    "\n",
    "    matrix = np.zeros((len(merged.T), len(merged.T)))\n",
    "\n",
    "    indi = 0\n",
    "    for i in merged.T.index:\n",
    "        indj = 0\n",
    "        for j in merged.T.index:\n",
    "            matrix[indi][indj] += np.array(merged[i]) @ np.array(merged[j])\n",
    "            indj+=1\n",
    "        indi+=1\n",
    "\n",
    "    for i in range(len(matrix)):\n",
    "        matrix[i] /= matrix[i][i]\n",
    "\n",
    "    # # diag = np.diag(matrix)\n",
    "    # matrix /= merged.shape[0]\n",
    "\n",
    "    # file_name = './Figures/' + name + '.pdf'\n",
    "    #\n",
    "    # plt.figure(figsize=(6, 6), dpi=100)\n",
    "    # ax = sb.heatmap(matrix, annot=True, cbar=False)\n",
    "    # ax.set_xticklabels(merged.columns, rotation=45)\n",
    "    # ax.set_yticklabels(merged.columns, rotation=0)\n",
    "    # plt.title(name)\n",
    "    # plt.savefig(file_name)\n",
    "    # plt.show()\n",
    "\n",
    "    ## version 1.0\n",
    "    # cm = matrix[4:, :4]\n",
    "    # accuracy_max = -np.Inf\n",
    "    # best_comb = None\n",
    "    # for comb in itertools.permutations([0, 1, 2, 3]):\n",
    "    #     acc = 0\n",
    "    #     i = 0\n",
    "    #     for j in comb:\n",
    "    #         acc += cm[i, j]\n",
    "    #         i += 1\n",
    "    #\n",
    "    #     if acc > accuracy_max:\n",
    "    #         accuracy_max = acc\n",
    "    #         best_comb = comb\n",
    "    #\n",
    "    # cm_with_order = np.concatenate([cm, np.array(best_comb).reshape(-1, 1)], axis=1)\n",
    "    # new_cm = cm_with_order[cm_with_order[:, 4].argsort()][:, :4]\n",
    "    #\n",
    "    # if plot:\n",
    "    #     plt.figure(figsize=(6, 6), dpi=100)\n",
    "    #     ax = sb.heatmap(new_cm, annot=True, cbar=False)\n",
    "    #     ax.set_yticklabels(['cluster_' + str(x) for x in range(1, 5)], rotation=0)\n",
    "    #     ax.set_xticklabels(['PAM50_' + str(x) for x in range(1, 5)], rotation=45)\n",
    "    #     plt.show()\n",
    "\n",
    "    # return accuracy_max\n",
    "\n",
    "\n",
    "    upper_mat = matrix[:4, 4:]\n",
    "    lower_mat = matrix[4:, :4]\n",
    "\n",
    "\n",
    "    best_upper_dist, best_lower_dist = np.Inf, np.Inf\n",
    "    best_upper_permu, best_lower_permu = None, None\n",
    "\n",
    "    ## version 2.0\n",
    "    for permu_mat in permutation_matrices:\n",
    "        upper_dist = np.sum(np.abs(permu_mat - upper_mat))\n",
    "        if upper_dist < best_upper_dist:\n",
    "            best_upper_dist = upper_dist\n",
    "            best_upper_permu = permu_mat\n",
    "\n",
    "        lower_dist = np.sum(np.abs(permu_mat - lower_mat.T))\n",
    "        if lower_dist < best_lower_dist:\n",
    "            best_lower_dist = lower_dist\n",
    "            best_lower_permu = permu_mat\n",
    "\n",
    "    error = best_upper_dist + best_lower_dist\n",
    "\n",
    "    lower_mat =  best_lower_permu @ lower_mat\n",
    "    new_matrix = np.hstack([np.vstack([matrix[:4, :4], lower_mat]), np.vstack([upper_mat, matrix[4:, 4:]])])\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(6, 6), dpi=100)\n",
    "        ax = sb.heatmap(new_matrix, annot=True, cbar=False)\n",
    "        ax.set_xticklabels(merged.columns, rotation=45)\n",
    "        ax.set_yticklabels(merged.columns, rotation=0)\n",
    "        plt.show()\n",
    "\n",
    "    if return_permutation:\n",
    "        return error, best_upper_permu, best_lower_permu\n",
    "    else:\n",
    "        return error"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "error = model_eval(Y, pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "error"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Model improvement"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.1 Feature selection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "error_list = []\n",
    "min_error = np.Inf\n",
    "feature_selected = None\n",
    "for i in range(X_scaled.shape[1]):\n",
    "\n",
    "    X_reduced = np.array(X_scaled.iloc[:, i]).reshape(-1, 1)\n",
    "\n",
    "    k_means = KMeans(n_clusters=4, algorithm='full').fit(X_reduced)\n",
    "    pred_ = k_means.labels_\n",
    "    error = model_eval(Y, pred_)\n",
    "    error_list.append(error)\n",
    "    if error < min_error:\n",
    "        min_error = error\n",
    "        feature_selected = X_scaled.columns[i]\n",
    "\n",
    "print(min_error)\n",
    "print(feature_selected)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_reduced = np.array(X_scaled[feature_selected]).reshape(-1, 1)\n",
    "k_means = KMeans(n_clusters=4, algorithm='full').fit(X_reduced)\n",
    "pred = k_means.labels_\n",
    "error = model_eval(Y, pred, False, True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.2 Model selection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
