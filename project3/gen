digraph {
	graph [size="13.95,13.95"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	1743401799008 [label="
 (32, 1, 28, 28)" fillcolor=darkolivegreen1]
	1743405600288 [label=TanhBackward0]
	1743405603552 -> 1743405600288
	1743405603552 [label=ConvolutionBackward0]
	1743405605040 -> 1743405603552
	1743405605040 [label=ReluBackward0]
	1743405600240 -> 1743405605040
	1743405600240 [label=NativeBatchNormBackward0]
	1743405603264 -> 1743405600240
	1743405603264 [label=ConvolutionBackward0]
	1743405603936 -> 1743405603264
	1743405603936 [label=ReluBackward0]
	1743405604272 -> 1743405603936
	1743405604272 [label=NativeBatchNormBackward0]
	1743388278544 -> 1743405604272
	1743388278544 [label=ConvolutionBackward0]
	1743388277344 -> 1743388278544
	1743388277344 [label=ReluBackward0]
	1743400059472 -> 1743388277344
	1743400059472 [label=NativeBatchNormBackward0]
	1743400059280 -> 1743400059472
	1743400059280 [label=ConvolutionBackward0]
	1743400058944 -> 1743400059280
	1743400058944 [label=ViewBackward0]
	1743400059088 -> 1743400058944
	1743400059088 [label=AddmmBackward0]
	1743400059664 -> 1743400059088
	1743400187152 [label="fc.bias
 (3136)" fillcolor=lightblue]
	1743400187152 -> 1743400059664
	1743400059664 [label=AccumulateGrad]
	1743400059376 -> 1743400059088
	1743400059376 [label=TBackward0]
	1743400059184 -> 1743400059376
	1743400187952 [label="fc.weight
 (3136, 100)" fillcolor=lightblue]
	1743400187952 -> 1743400059184
	1743400059184 [label=AccumulateGrad]
	1743400059136 -> 1743400059280
	1743345278688 [label="trans_conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1743345278688 -> 1743400059136
	1743400059136 [label=AccumulateGrad]
	1743400064848 -> 1743400059280
	1743345286528 [label="trans_conv1.bias
 (64)" fillcolor=lightblue]
	1743345286528 -> 1743400064848
	1743400064848 [label=AccumulateGrad]
	1743400060480 -> 1743400059472
	1743420718144 [label="batch_norm1.weight
 (64)" fillcolor=lightblue]
	1743420718144 -> 1743400060480
	1743400060480 [label=AccumulateGrad]
	1743400058992 -> 1743400059472
	1743345282048 [label="batch_norm1.bias
 (64)" fillcolor=lightblue]
	1743345282048 -> 1743400058992
	1743400058992 [label=AccumulateGrad]
	1743388272880 -> 1743388278544
	1743345286208 [label="trans_conv2.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	1743345286208 -> 1743388272880
	1743388272880 [label=AccumulateGrad]
	1743388278352 -> 1743388278544
	1743345272928 [label="trans_conv2.bias
 (32)" fillcolor=lightblue]
	1743345272928 -> 1743388278352
	1743388278352 [label=AccumulateGrad]
	1743388278592 -> 1743405604272
	1743345285808 [label="batch_norm2.weight
 (32)" fillcolor=lightblue]
	1743345285808 -> 1743388278592
	1743388278592 [label=AccumulateGrad]
	1743388278688 -> 1743405604272
	1743345280848 [label="batch_norm2.bias
 (32)" fillcolor=lightblue]
	1743345280848 -> 1743388278688
	1743388278688 [label=AccumulateGrad]
	1743405603168 -> 1743405603264
	1743345282208 [label="trans_conv3.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	1743345282208 -> 1743405603168
	1743405603168 [label=AccumulateGrad]
	1743405602304 -> 1743405603264
	1743345277008 [label="trans_conv3.bias
 (16)" fillcolor=lightblue]
	1743345277008 -> 1743405602304
	1743405602304 [label=AccumulateGrad]
	1743405604176 -> 1743405600240
	1743406747536 [label="batch_norm3.weight
 (16)" fillcolor=lightblue]
	1743406747536 -> 1743405604176
	1743405604176 [label=AccumulateGrad]
	1743405603648 -> 1743405600240
	1743406746336 [label="batch_norm3.bias
 (16)" fillcolor=lightblue]
	1743406746336 -> 1743405603648
	1743405603648 [label=AccumulateGrad]
	1743405603600 -> 1743405603552
	1743406747616 [label="trans_conv4.weight
 (16, 1, 3, 3)" fillcolor=lightblue]
	1743406747616 -> 1743405603600
	1743405603600 [label=AccumulateGrad]
	1743405600720 -> 1743405603552
	1743401796688 [label="trans_conv4.bias
 (1)" fillcolor=lightblue]
	1743401796688 -> 1743405600720
	1743405600720 [label=AccumulateGrad]
	1743405600288 -> 1743401799008
}
